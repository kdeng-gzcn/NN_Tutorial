{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "train = datasets.MNIST(\n",
    "    root='',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([transforms.ToTensor()])\n",
    ")\n",
    "\n",
    "test = datasets.MNIST(\n",
    "    root='',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([transforms.ToTensor()])\n",
    ")\n",
    "\n",
    "trainset = torch.utils.data.DataLoader(\n",
    "    train,\n",
    "    batch_size=16,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "testset = torch.utils.data.DataLoader(\n",
    "    test,\n",
    "    batch_size=16,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x)) # all neurons have the same active function\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.log_softmax(self.fc4(x), dim=1) \n",
    "        # dim here is more likely to be axis= in pandas, it makes sure our y is distribution across numbers instead of batched\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.2091, -2.2421, -2.1911, -2.3542, -2.3493, -2.2295, -2.4042, -2.3938,\n",
       "         -2.2886, -2.3952]], grad_fn=<LogSoftmaxBackward0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.rand([28, 28])\n",
    "X = X.view([-1, 28 * 28])\n",
    "net = Net()\n",
    "output = net(X)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss\n",
    "measure of how wrong is the model\n",
    "\n",
    "our goal is to keep decreasing the loss\n",
    "\n",
    "## Optimizer\n",
    "its job is to go through the computation and adjust the weights based on loss(gradient)\n",
    "\n",
    "learning rate: the time we used in lowring the loss is based on learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(\n",
    "    net.parameters(), # all adjustable params in model\n",
    "    lr=1e-3 # 0.001\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- consider transfer learning\n",
    "the first layers in the net may be good at small and general types of image recognition tasks\n",
    "\n",
    "the later layers may be good at exact tasks you designed\n",
    "\n",
    "in this case, you need to freeze the first layers\n",
    "\n",
    "- learning rate\n",
    "\n",
    "learning rate is to avoid overfitting, we dont want loss to be 0, so we control the size\n",
    "\n",
    "we want go batches and batched but only capture the principle features\n",
    "\n",
    "- no perfect lr\n",
    "\n",
    "thats what we call delaying lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss in trainning process\n",
    "we compute the loss, and adjust weights based on it.\n",
    "\n",
    "our expectation is the loss will be lower, and accuracy follows.\n",
    "\n",
    "high accuracy is not our task for model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Epochs\n",
    "we want to go through our full data for several times.\n",
    "\n",
    "one time is called epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 0.08076558262109756\n",
      "1: 0.0705980584025383\n",
      "2: 0.0006412824732251465\n"
     ]
    }
   ],
   "source": [
    "epoch_num = 3\n",
    "\n",
    "for epoch in range(epoch_num):\n",
    "    for data in trainset:\n",
    "        X, y = data\n",
    "        net.zero_grad() # every time before input numbers into network\n",
    "        # if you dont 0 the gradient, they will add together\n",
    "        # you can view the gradient as a container which contains the loss\n",
    "        # then the optimizer go through and use these gradients to optimize the weights\n",
    "        output = net(X.view([-1, 28 * 28]))\n",
    "        # how wrong are we!\n",
    "        loss = F.nll_loss(output, y) # loss metric function\n",
    "        loss.backward() # pytorch magic!\n",
    "        optimizer.step() # in each step, update parans one time\n",
    "\n",
    "    print(f'{epoch}: {loss}')\n",
    "\n",
    "\n",
    "# note that batch data has 2 advantages\n",
    "# 1. it decreased training time\n",
    "# 2, suitable for weak GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.97345\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    # under frozen environment, lets do somethings\n",
    "    # especially validating something\n",
    "\n",
    "    # net.train(), net.eval(), these are modes\n",
    "    for data in trainset:\n",
    "        X, y = data\n",
    "        output = net(X.view([-1, 28 * 28])) # remember to flatten\n",
    "\n",
    "        for idx, i in enumerate(output): # why? what is output? why enumerate\n",
    "            if torch.argmax(i) == y[idx]:\n",
    "                correct += 1\n",
    "\n",
    "            total += 1\n",
    "\n",
    "print(f'Accuracy: {correct / total}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check last batch data 16 Xs\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.imshow(X[3].view([28, 28]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check our net result\n",
    "torch.argmax(\n",
    "    net(X[3].view([-1, 28 * 28]))[0] # torch.argmax return list, here is scale case\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
