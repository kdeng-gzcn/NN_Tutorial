{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data\n",
    "note that in the work, preparing data will 90% of time\n",
    "\n",
    "its really important to prepare a clean dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we are going to use mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# common sense for overfitting\n",
    "we focus on the model performance on new data, that's is test dataset\n",
    "\n",
    "if we train a model for a long enough time, we will get an overfitting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get train dataset and test dataset\n",
    "train = datasets.MNIST(\n",
    "    root=\"\", \n",
    "    train=True, \n",
    "    download=True, \n",
    "    transform=transforms.Compose([transforms.ToTensor()])\n",
    "    )\n",
    "\n",
    "test = datasets.MNIST(\n",
    "    root=\"\", \n",
    "    train=False, \n",
    "    download=True, \n",
    "    transform=transforms.Compose([transforms.ToTensor()])\n",
    "    )\n",
    "\n",
    "# note that here we use build-in transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torchvision.datasets.mnist.MNIST, torchvision.datasets.mnist.MNIST)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train), type(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils\n",
    "import torch.utils.data\n",
    "\n",
    "\n",
    "trainset = torch.utils.data.DataLoader(\n",
    "    train, \n",
    "    batch_size=16, \n",
    "    shuffle=True\n",
    "    )\n",
    "testset = torch.utils.data.DataLoader(\n",
    "    test, \n",
    "    batch_size=16, \n",
    "    shuffle=True\n",
    "    )\n",
    "\n",
    "# batchsize is always base 8, note that this is no reason\n",
    "# batchsize is not as big as possible\n",
    "# usually between 8 to 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST\n",
    "a hand-drawn dataset of numbers from 0 to 9\n",
    "- 28 * 28 image \n",
    "- if `shuffle=False`, the network will be like out put 0, then 1, then 2, ..., finally 9, all images will be classified 9\n",
    "- if `shuffle=True`, the network will learn the general principles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]]), tensor([9, 9, 5, 1, 2, 0, 1, 8, 5, 6, 3, 9, 4, 7, 9, 6])]\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "for data in trainset:\n",
    "    print(data)\n",
    "    print(type(data))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can see that, the data is a list including [tensor_X, tensor_label], where the size is 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3569, 0.9569,\n",
       "           0.9843, 0.2118, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0353, 0.2314, 0.8863, 0.9961, 0.9961,\n",
       "           0.9882, 0.2824, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0157, 0.6627, 0.9961, 0.9961, 1.0000, 0.9882,\n",
       "           0.5098, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0235, 0.6667, 0.9961, 0.9961, 0.7451, 0.6039, 0.2824,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.4196, 0.9961, 0.8706, 0.2627, 0.0471, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0863, 0.8275, 0.9961, 0.4471, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.4471, 0.9961, 0.7608, 0.0118, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.5529, 0.9961, 0.4431, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.5059, 0.8941, 0.1098, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.8275, 0.9961, 0.2941, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0745, 0.9451, 0.9961, 0.1843, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.5529, 0.9961, 0.2941, 0.0000, 0.0000, 0.0000, 0.0000, 0.0588,\n",
       "           0.7608, 0.9961, 0.9255, 0.1176, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.4627, 0.9961, 0.8745, 0.1176, 0.0000, 0.0000, 0.0706, 0.7804,\n",
       "           0.9961, 0.9961, 0.4431, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0235, 0.7765, 0.9961, 0.9294, 0.7490, 0.8863, 0.9176, 0.9961,\n",
       "           0.9961, 0.9961, 0.2510, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0980, 0.4824, 0.9451, 0.9569, 0.9569, 0.9608, 0.9922,\n",
       "           0.9961, 0.8588, 0.0431, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8863,\n",
       "           0.9961, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1451, 0.9451,\n",
       "           0.9608, 0.0235, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2627, 0.9961,\n",
       "           0.6275, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5176, 0.9961,\n",
       "           0.2196, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6275, 0.9961,\n",
       "           0.3020, 0.0000, 0.0000, 0.0863, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4510, 0.9961,\n",
       "           0.7686, 0.3608, 0.6667, 0.3294, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0667, 0.6392,\n",
       "           0.9961, 0.9961, 0.4000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000]]]),\n",
       " tensor(9))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# based on above analysis, we try to extract image 5 and label 5\n",
    "x, y = data[0][0], data[1][0]\n",
    "# here data[0] is 3dim tensor, data[0][0] is 3dim(actually 2dim) matrix\n",
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# shape of tensor\n",
    "its quite important, although here is 3dim, but its actually 2dim, this would lead to some problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaEAAAGdCAYAAAC7EMwUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAaLUlEQVR4nO3df3DU953f8deCxFrQ1V4VkHZlZEVNYZxBlJ6BACo/BA0qypgay2mx3cmIacLYsaClso8JYebQ5A/kwQflrrJJw3gIXCAwc8WYFgasHEiEkcnJVK4Z4hJxCKMMUlU0tlbIeEHw6R+UvayFRb7LLm+t9vmY2Rm0+33z/fD11zz99a6+8jnnnAAAMDDGegEAgMxFhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgJks6wV82Z07d3T16lUFAgH5fD7r5QAAPHLOqb+/X4WFhRozZvhrnREXoatXr6qoqMh6GQCAh9TZ2anJkycPu82Ii1AgEJAkzdd3lKVs49UAALwa1C2d1tHY3+fDSVmE3nrrLb3xxhvq6urStGnTtH37di1YsOCBc/f+F1yWspXlI0IAkHb+/x1J/5i3VFLywYQDBw5o3bp12rhxo9ra2rRgwQJVVlbqypUrqdgdACBNpSRC27Zt0/e//3394Ac/0De/+U1t375dRUVF2rFjRyp2BwBIU0mP0M2bN3X27FlVVFTEPV9RUaGWlpYh20ejUUUikbgHACAzJD1C165d0+3bt1VQUBD3fEFBgbq7u4dsX19fr2AwGHvwyTgAyBwp+2bVL78h5Zy775tUGzZsUF9fX+zR2dmZqiUBAEaYpH86buLEiRo7duyQq56enp4hV0eS5Pf75ff7k70MAEAaSPqV0Lhx4zRz5kw1NjbGPd/Y2KiysrJk7w4AkMZS8n1CtbW1+t73vqdZs2Zp3rx5+tnPfqYrV67o5ZdfTsXuAABpKiURWrlypXp7e/WTn/xEXV1dKi0t1dGjR1VcXJyK3QEA0pTPOeesF/GHIpGIgsGgyvUMd0wAgDQ06G6pSe+qr69Pubm5w27Lj3IAAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzGRZLwDIRD1ryjzP/Pf1WzzP5I0Z53lGkp7+9694nsl+74OE9oXMxpUQAMAMEQIAmEl6hOrq6uTz+eIeoVAo2bsBAIwCKXlPaNq0afrVr34V+3rs2LGp2A0AIM2lJEJZWVlc/QAAHigl7wm1t7ersLBQJSUlev7553Xp0qWv3DYajSoSicQ9AACZIekRmjNnjvbs2aPjx49r586d6u7uVllZmXp7e++7fX19vYLBYOxRVFSU7CUBAEaopEeosrJSzz33nKZPn65vf/vbOnLkiCRp9+7d991+w4YN6uvriz06OzuTvSQAwAiV8m9WnTBhgqZPn6729vb7vu73++X3+1O9DADACJTy7xOKRqP6+OOPFQ6HU70rAECaSXqEXnvtNTU3N6ujo0O/+c1v9N3vfleRSETV1dXJ3hUAIM0l/X/H/f73v9cLL7yga9euadKkSZo7d67OnDmj4uLiZO8KAJDmkh6h/fv3J/u3BDwbEwgkNHdj4ZOeZ/7sL//a88yynP/peUYa73liULcT2I9042ve/2rITmhPyHTcOw4AYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMJPyH2oHPCxf9jjPM737Qwnt6/1//l8TmvNqrM/7f/9F3S3PM9/8m7WeZyRpyi/PJDQHeMWVEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMxwF208UmMee8zzzKcHJ3ueeX/GAc8ziar+ZInnmb/7pNjzzNcO53ie4W7YGOm4EgIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzHADUzxSn7z6lOeZczMaPM/8t4F/7HlGkv7qx897nsn92995nin59H95ngFGI66EAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAz3MAUCcsqLvI884MXjqVgJUP9+f4XE5or/pv3Pc/cTmhPACSuhAAAhogQAMCM5widOnVKy5cvV2FhoXw+nw4dOhT3unNOdXV1KiwsVE5OjsrLy3X+/PlkrRcAMIp4jtDAwIBmzJihhob7/6CxLVu2aNu2bWpoaFBra6tCoZCWLl2q/v7+h14sAGB08fzBhMrKSlVWVt73Neectm/fro0bN6qqqkqStHv3bhUUFGjfvn166aWXHm61AIBRJanvCXV0dKi7u1sVFRWx5/x+vxYtWqSWlpb7zkSjUUUikbgHACAzJDVC3d3dkqSCgoK45wsKCmKvfVl9fb2CwWDsUVTk/WO/AID0lJJPx/l8vrivnXNDnrtnw4YN6uvriz06OztTsSQAwAiU1G9WDYVCku5eEYXD4djzPT09Q66O7vH7/fL7/clcBgAgTST1SqikpEShUEiNjY2x527evKnm5maVlZUlc1cAgFHA85XQ9evXdfHixdjXHR0d+vDDD5WXl6cnnnhC69at0+bNmzVlyhRNmTJFmzdv1vjx4/Xii4ndRgUAMHp5jtAHH3ygxYsXx76ura2VJFVXV+vnP/+51q9frxs3buiVV17Rp59+qjlz5ui9995TIBBI3qoBAKOCzznnrBfxhyKRiILBoMr1jLJ82dbLwTA++ck8zzPnv/+m55mXf7/A80znv4h6npEkNziY0ByAfzDobqlJ76qvr0+5ubnDbsu94wAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGAmqT9ZFZklGn40d5z+9bEZnmeKB1tSsJLMcXH7XM8zO55+2/PM9u/8a88zt3/3955nMHJxJQQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmOEGpkjY2nl/+0j28yftdx7JfkajrMcLE5p779m/8Dzz9azxnmfeKMj1PDPmd55HMIJxJQQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmOEGpkjYf3n/X3qe+Y/fuZiClWSGsZMmeZ4pPNiX0L4SuRnpuZu3PM9kX7vueea25wmMZFwJAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmuIEpEpb9fx/N6fNnf77P88zbZ/9VQvu6/XF7QnNeZYVDnmem/I9rnme2hv7O80yint/znzzPFH/ckoKVIJ1wJQQAMEOEAABmPEfo1KlTWr58uQoLC+Xz+XTo0KG411etWiWfzxf3mDt3brLWCwAYRTxHaGBgQDNmzFBDQ8NXbrNs2TJ1dXXFHkePHn2oRQIARifP7yxXVlaqsrJy2G38fr9CIe9vvAIAMktK3hNqampSfn6+pk6dqtWrV6unp+crt41Go4pEInEPAEBmSHqEKisrtXfvXp04cUJbt25Va2urlixZomg0et/t6+vrFQwGY4+ioqJkLwkAMEIl/Rs9Vq5cGft1aWmpZs2apeLiYh05ckRVVVVDtt+wYYNqa2tjX0ciEUIEABki5d9tGA6HVVxcrPb2+38ToN/vl9/vT/UyAAAjUMq/T6i3t1ednZ0Kh8Op3hUAIM14vhK6fv26Ll68GPu6o6NDH374ofLy8pSXl6e6ujo999xzCofDunz5sn784x9r4sSJevbZZ5O6cABA+vMcoQ8++ECLFy+OfX3v/Zzq6mrt2LFD586d0549e/TZZ58pHA5r8eLFOnDggAKBQPJWDQAYFXzOOWe9iD8UiUQUDAZVrmeU5cu2Xg6GMeaxxzzPTDl92/PMfw7/xvPM+Vs3Pc9I0l90VXieWTnJ+01CJ43t9zwzc9xYzzOPUvmaH3qeGf+O93+2GPkG3S016V319fUpNzd32G25dxwAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMpPwnq2L0uvPFF55n/v7fft3zzJMv13ieObbyDc8zkrT58aMJzXmVyP2w7yjH88wY+RLYk7S3P9/zTODk//Y84/2e6hhtuBICAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMxwA1M8UoOXLnue+Sfrvc+8sn6+55mR7j9c9H6D0GU5nye0r7/c9m88z0z87P2E9oXMxpUQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGG5gCBnx/Os3zzJPZpz3P9Nz2PCJJyt/T5nnmTmK7QobjSggAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMMMNTAED17/xjzzPfD1rvOeZf3bme55nJGnyF+cTmgO84koIAGCGCAEAzHiKUH19vWbPnq1AIKD8/HytWLFCFy5ciNvGOae6ujoVFhYqJydH5eXlOn+eS3sAwFCeItTc3KyamhqdOXNGjY2NGhwcVEVFhQYGBmLbbNmyRdu2bVNDQ4NaW1sVCoW0dOlS9ff3J33xAID05umDCceOHYv7eteuXcrPz9fZs2e1cOFCOee0fft2bdy4UVVVVZKk3bt3q6CgQPv27dNLL72UvJUDANLeQ70n1NfXJ0nKy8uTJHV0dKi7u1sVFRWxbfx+vxYtWqSWlpb7/h7RaFSRSCTuAQDIDAlHyDmn2tpazZ8/X6WlpZKk7u5uSVJBQUHctgUFBbHXvqy+vl7BYDD2KCoqSnRJAIA0k3CE1qxZo48++ki//OUvh7zm8/nivnbODXnung0bNqivry/26OzsTHRJAIA0k9A3q65du1aHDx/WqVOnNHny5NjzoVBI0t0ronA4HHu+p6dnyNXRPX6/X36/P5FlAADSnKcrIeec1qxZo4MHD+rEiRMqKSmJe72kpEShUEiNjY2x527evKnm5maVlZUlZ8UAgFHD05VQTU2N9u3bp3fffVeBQCD2Pk8wGFROTo58Pp/WrVunzZs3a8qUKZoyZYo2b96s8ePH68UXX0zJHwAAkL48RWjHjh2SpPLy8rjnd+3apVWrVkmS1q9frxs3buiVV17Rp59+qjlz5ui9995TIBBIyoIBAKOHpwg55x64jc/nU11dnerq6hJdEzDqXV30aPaTv9P7TU+BR4l7xwEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMBMQj9ZFcDDySm8/kj283l+Yv+Kj0vyOr5KVnGR55nBTzpTsBJY4UoIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADDDDUwBA4O/zfU+NNf7yMy1bd6HJLUEyzzPPFbZ43lm8J1Jnme+tpMbmI4mXAkBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGa4gSlg4J++ecnzzJ9O/3eeZ9pm7/U8I0n6UYvnkRl/tcbzzOM7ve8HowtXQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGW5gChgY7P4/nmfCK7zPfEdPeZ5J1OPiZqTwjishAIAZIgQAMOMpQvX19Zo9e7YCgYDy8/O1YsUKXbhwIW6bVatWyefzxT3mzp2b1EUDAEYHTxFqbm5WTU2Nzpw5o8bGRg0ODqqiokIDAwNx2y1btkxdXV2xx9GjR5O6aADA6ODpgwnHjh2L+3rXrl3Kz8/X2bNntXDhwtjzfr9foVAoOSsEAIxaD/WeUF9fnyQpLy8v7vmmpibl5+dr6tSpWr16tXp6er7y94hGo4pEInEPAEBmSDhCzjnV1tZq/vz5Ki0tjT1fWVmpvXv36sSJE9q6dataW1u1ZMkSRaPR+/4+9fX1CgaDsUdRUVGiSwIApBmfc84lMlhTU6MjR47o9OnTmjx58ldu19XVpeLiYu3fv19VVVVDXo9Go3GBikQiKioqUrmeUZYvO5GlAQAMDbpbatK76uvrU25u7rDbJvTNqmvXrtXhw4d16tSpYQMkSeFwWMXFxWpvb7/v636/X36/P5FlAADSnKcIOee0du1avfPOO2pqalJJSckDZ3p7e9XZ2alwOJzwIgEAo5On94Rqamr0i1/8Qvv27VMgEFB3d7e6u7t148YNSdL169f12muv6f3339fly5fV1NSk5cuXa+LEiXr22WdT8gcAAKQvT1dCO3bskCSVl5fHPb9r1y6tWrVKY8eO1blz57Rnzx599tlnCofDWrx4sQ4cOKBAIJC0RQMARgfP/ztuODk5OTp+/PhDLQgAkDm4dxwAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwEyW9QK+zDknSRrULckZLwYA4Nmgbkn6h7/PhzPiItTf3y9JOq2jxisBADyM/v5+BYPBYbfxuT8mVY/QnTt3dPXqVQUCAfl8vrjXIpGIioqK1NnZqdzcXKMV2uM43MVxuIvjcBfH4a6RcBycc+rv71dhYaHGjBn+XZ8RdyU0ZswYTZ48edhtcnNzM/oku4fjcBfH4S6Ow10ch7usj8ODroDu4YMJAAAzRAgAYCatIuT3+7Vp0yb5/X7rpZjiONzFcbiL43AXx+GudDsOI+6DCQCAzJFWV0IAgNGFCAEAzBAhAIAZIgQAMJNWEXrrrbdUUlKixx57TDNnztSvf/1r6yU9UnV1dfL5fHGPUChkvayUO3XqlJYvX67CwkL5fD4dOnQo7nXnnOrq6lRYWKicnByVl5fr/PnzNotNoQcdh1WrVg05P+bOnWuz2BSpr6/X7NmzFQgElJ+frxUrVujChQtx22TC+fDHHId0OR/SJkIHDhzQunXrtHHjRrW1tWnBggWqrKzUlStXrJf2SE2bNk1dXV2xx7lz56yXlHIDAwOaMWOGGhoa7vv6li1btG3bNjU0NKi1tVWhUEhLly6N3YdwtHjQcZCkZcuWxZ0fR4+OrnswNjc3q6amRmfOnFFjY6MGBwdVUVGhgYGB2DaZcD78McdBSpPzwaWJb33rW+7ll1+Oe+7JJ590P/rRj4xW9Oht2rTJzZgxw3oZpiS5d955J/b1nTt3XCgUcq+//nrsuS+++MIFg0H305/+1GCFj8aXj4NzzlVXV7tnnnnGZD1Wenp6nCTX3NzsnMvc8+HLx8G59Dkf0uJK6ObNmzp79qwqKirinq+oqFBLS4vRqmy0t7ersLBQJSUlev7553Xp0iXrJZnq6OhQd3d33Lnh9/u1aNGijDs3JKmpqUn5+fmaOnWqVq9erZ6eHuslpVRfX58kKS8vT1Lmng9fPg73pMP5kBYRunbtmm7fvq2CgoK45wsKCtTd3W20qkdvzpw52rNnj44fP66dO3equ7tbZWVl6u3ttV6amXv//DP93JCkyspK7d27VydOnNDWrVvV2tqqJUuWKBqNWi8tJZxzqq2t1fz581VaWiopM8+H+x0HKX3OhxF3F+3hfPlHOzjnhjw3mlVWVsZ+PX36dM2bN0/f+MY3tHv3btXW1hquzF6mnxuStHLlytivS0tLNWvWLBUXF+vIkSOqqqoyXFlqrFmzRh999JFOnz495LVMOh++6jiky/mQFldCEydO1NixY4f8l0xPT8+Q/+LJJBMmTND06dPV3t5uvRQz9z4dyLkxVDgcVnFx8ag8P9auXavDhw/r5MmTcT/6JdPOh686DvczUs+HtIjQuHHjNHPmTDU2NsY939jYqLKyMqNV2YtGo/r4448VDoetl2KmpKREoVAo7ty4efOmmpubM/rckKTe3l51dnaOqvPDOac1a9bo4MGDOnHihEpKSuJez5Tz4UHH4X5G7Plg+KEIT/bv3++ys7Pd22+/7X7729+6devWuQkTJrjLly9bL+2RefXVV11TU5O7dOmSO3PmjHv66addIBAY9cegv7/ftbW1uba2NifJbdu2zbW1tblPPvnEOefc66+/7oLBoDt48KA7d+6ce+GFF1w4HHaRSMR45ck13HHo7+93r776qmtpaXEdHR3u5MmTbt68ee7xxx8fVcfhhz/8oQsGg66pqcl1dXXFHp9//nlsm0w4Hx50HNLpfEibCDnn3JtvvumKi4vduHHj3FNPPRX3ccRMsHLlShcOh112drYrLCx0VVVV7vz589bLSrmTJ086SUMe1dXVzrm7H8vdtGmTC4VCzu/3u4ULF7pz587ZLjoFhjsOn3/+uauoqHCTJk1y2dnZ7oknnnDV1dXuypUr1stOqvv9+SW5Xbt2xbbJhPPhQcchnc4HfpQDAMBMWrwnBAAYnYgQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM/8PjeOz3Y80ozwAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.imshow(x.view([28, 28])) # .view(28, 28)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the model doesnt know how good we can get, so it will try its best to decrease the loss\n",
    "- imagine the situation that the number distribution is not uniform\n",
    "- - then the model will try to output the number having max frequency, its called local optimization\n",
    "Hence, we really need our dataset to be balanced "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 5923,\n",
       " 1: 6742,\n",
       " 2: 5958,\n",
       " 3: 6131,\n",
       " 4: 5842,\n",
       " 5: 5421,\n",
       " 6: 5918,\n",
       " 7: 6265,\n",
       " 8: 5851,\n",
       " 9: 5949}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the dataset if its balanced\n",
    "total = 0\n",
    "counter_dict = {\n",
    "    0:0,\n",
    "    1:0,\n",
    "    2:0,\n",
    "    3:0,\n",
    "    4:0,\n",
    "    5:0,\n",
    "    6:0,\n",
    "    7:0,\n",
    "    8:0,\n",
    "    9:0\n",
    "}\n",
    "# the key is int, the value of the key is also int\n",
    "\n",
    "for data in trainset:\n",
    "    Xs, ys = data\n",
    "    for y in ys: # this loop is counting numbers\n",
    "        counter_dict[int(y)] += 1 # change tensor to int\n",
    "        total += 1\n",
    "\n",
    "counter_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 9.87%\n",
      "1: 11.24%\n",
      "2: 9.93%\n",
      "3: 10.22%\n",
      "4: 9.74%\n",
      "5: 9.04%\n",
      "6: 9.86%\n",
      "7: 10.44%\n",
      "8: 9.75%\n",
      "9: 9.92%\n"
     ]
    }
   ],
   "source": [
    "for number in counter_dict:\n",
    "    print(f'{number}: {round(counter_dict[number] / total * 100, 2)}%')\n",
    "\n",
    "# the dataset is balanced enough\n",
    "# its not perfectly 10%, but its acceptable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In the End\n",
    "emphersize again the data is much more important than nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
